{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddee535e-59b8-4375-83d0-dc009340efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSSM-based Delta Pose Predictor for Ultrasound Images\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import csv\n",
    "import cv2\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8913d04c-377d-476b-8955-8e9898e59eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.__version__)            \n",
    "print(torch.cuda.is_available())     \n",
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c3070b1-33c4-436e-852e-ea3ee01462f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Data Root\n",
    "data_root = '.'  # /path/to/data\n",
    "\n",
    "# Set train/test folder names\n",
    "train_dirs = {\n",
    "    \"frames_0513_06\",# \"frames_0513_07\", \"frames_0513_08\", \"frames_0513_09\",\n",
    "    \"frames_0513_11\",# \"frames_0513_12\", \"frames_0513_13\", \"frames_0513_14\", \"frames_0513_15\",\n",
    "    \"frames_0513_16\",# \"frames_0513_17\", \"frames_0513_19\", \"frames_0513_20\",\n",
    "    \"frames_0513_22\",# \"frames_0513_22\", \"frames_0513_22\", \"frames_0513_23\", \"frames_0513_24\", \"frames_0513_25\", \"frames_0513_26\"\n",
    "}\n",
    "\n",
    "test_dirs = {\n",
    "    \"frames_0513_01\", #\"frames_0513_02\", \"frames_0513_03\", \"frames_0513_04\", \"frames_0513_05\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c617969d-12ba-4211-81a2-9ae27de1769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Combine CSVs ============\n",
    "def combine_pose_csvs_with_foldername(root_folder, output_csv=\"poses_combined.csv\"):\n",
    "    all_data = []\n",
    "\n",
    "    for file in sorted(os.listdir(root_folder)):\n",
    "        if not file.endswith(\"_final_data.csv\"):\n",
    "            continue\n",
    "\n",
    "        csv_path = os.path.join(root_folder, file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # ex: 0513_01_final_data.csv → frames_0513_01\n",
    "        folder_name = \"frames_\" + file.replace(\"_final_data.csv\", \"\")\n",
    "\n",
    "        # Update Filename Column: → frames_0513_01/frame_0000.png\n",
    "        df[\"Filename\"] = df[\"Filename\"].apply(lambda x: f\"{folder_name}/{x}\")\n",
    "        all_data.append(df)\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"⚠️ No Valid File Found\")\n",
    "        return\n",
    "\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    combined_df.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Saved Combined CSV to：{output_csv}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02618978-809d-42b2-b1dc-6a74c16aec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved Combined CSV to：poses_combined.csv\n"
     ]
    }
   ],
   "source": [
    "combine_pose_csvs_with_foldername(data_root, \"poses_combined.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39a15389-93de-438a-91e2-1ee7c5a83e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Sequence Ultrasound Dataset ===\n",
    "class SequenceUltrasoundDataset(Dataset):\n",
    "    def __init__(self, csv_path, root_dirs, sequence_length=5, image_size=(256, 256)):\n",
    "        self.samples = []\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        df['folder'] = df['Filename'].apply(lambda x: x.split('/')[0])\n",
    "        df = df.rename(columns={\n",
    "            'Filename': 'img_path',\n",
    "            'X (mm)': 'tx', 'Y (mm)': 'ty', 'Z (mm)': 'tz',\n",
    "            'Roll (deg)': 'rx', 'Pitch (deg)': 'ry', 'Yaw (deg)': 'rz'\n",
    "        })\n",
    "\n",
    "        for dir_ in root_dirs:\n",
    "            group = df[df['folder'] == dir_].sort_values('img_path')\n",
    "            frames = group.to_dict('records')\n",
    "            for i in range(len(frames) - sequence_length):\n",
    "                seq = frames[i:i + sequence_length + 1]\n",
    "                self.samples.append(seq)\n",
    "\n",
    "        self.sequence_length = sequence_length\n",
    "        self.image_size = image_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.samples[idx]\n",
    "        imgs, poses, delta_poses = [], [], []\n",
    "        for item in seq:\n",
    "            img_path = item['img_path']\n",
    "            if not os.path.exists(img_path):\n",
    "                raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                raise ValueError(f\"Cannot read image: {img_path}\")\n",
    "            img = self.transform(img)\n",
    "            pose = np.array([\n",
    "                item['tx'], item['ty'], item['tz'],\n",
    "                item['rx'], item['ry'], item['rz']\n",
    "            ], dtype=np.float32)\n",
    "            imgs.append(img)\n",
    "            poses.append(pose)\n",
    "\n",
    "        poses = torch.tensor(np.array(poses), dtype=torch.float32)\n",
    "        delta_poses = poses[1:] - poses[:-1]\n",
    "        \n",
    "        return (\n",
    "            torch.stack(imgs[:-1]),       # [T, 1, H, W]\n",
    "            delta_poses                  # [T, 6]\n",
    "        )\n",
    "\n",
    "# === Inference Ultrasound Dataset No Goal ===\n",
    "class InferenceUltrasoundDatasetNoGoal(Dataset):\n",
    "    def __init__(self, csv_path, root_dirs, init_len=5, inf_len=15, image_size=(256, 256)):\n",
    "        self.samples = []\n",
    "        self.inf_len = inf_len\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df['folder'] = df['Filename'].apply(lambda x: x.split('/')[0])\n",
    "        df = df.rename(columns={\n",
    "            'Filename': 'img_path',\n",
    "            'X (mm)': 'tx', 'Y (mm)': 'ty', 'Z (mm)': 'tz',\n",
    "            'Roll (deg)': 'rx', 'Pitch (deg)': 'ry', 'Yaw (deg)': 'rz'\n",
    "        })\n",
    "\n",
    "        for dir_ in root_dirs:\n",
    "            group = df[df['folder'] == dir_].sort_values('img_path').reset_index(drop=True)\n",
    "            frames = group.to_dict('records')\n",
    "            num_frames = len(frames)\n",
    "            if num_frames <= init_len + inf_len:\n",
    "                continue\n",
    "\n",
    "            # generate (init_seq, inf_seq) pair\n",
    "            for start_idx in range(0, num_frames - init_len - inf_len + 1):\n",
    "                init_seq = frames[start_idx : start_idx + init_len]\n",
    "                inf_seq = frames[start_idx + init_len : start_idx + init_len + inf_len]\n",
    "                sample = {\n",
    "                    'init_sequence': init_seq,\n",
    "                    'inference_sequence': inf_seq,\n",
    "                    'sequence_name': dir_\n",
    "                }\n",
    "                self.samples.append(sample)\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _load_image(self, img_path):\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Cannot read image: {img_path}\")\n",
    "        return self.transform(img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "\n",
    "        init_imgs = [self._load_image(x['img_path']) for x in item['init_sequence']]\n",
    "        inf_imgs = [self._load_image(x['img_path']) for x in item['inference_sequence']]\n",
    "\n",
    "        inf_poses = [\n",
    "            np.array([\n",
    "                x['tx'], x['ty'], x['tz'],\n",
    "                x['rx'], x['ry'], x['rz']\n",
    "            ], dtype=np.float32)\n",
    "            for x in item['inference_sequence']\n",
    "        ]\n",
    "\n",
    "        delta_poses = np.diff(np.stack(inf_poses, axis=0), axis=0)  # [T-1, 6]\n",
    "\n",
    "        return {\n",
    "            'sequence_name': item['sequence_name'],\n",
    "            'init_images': torch.stack(init_imgs),                   # [init_len, 1, H, W]\n",
    "            'inference_images': torch.stack(inf_imgs),               # [T, 1, H, W]\n",
    "            'ground_truth_delta_poses': torch.tensor(delta_poses, dtype=torch.float32),  # [T-1, 6]\n",
    "        }\n",
    "\n",
    "\n",
    "# === Encoder ===\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 4, stride=2, padding=1), nn.InstanceNorm2d(32), nn.ReLU(),  # 256→128\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1), nn.InstanceNorm2d(64), nn.ReLU(),  # 128→64\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1), nn.InstanceNorm2d(128), nn.ReLU(),  # 64→32\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1), nn.InstanceNorm2d(256), nn.ReLU()  # 32→16\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_mu = nn.Linear(256 * 16 * 16, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(256 * 16 * 16, latent_dim)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        std = F.softplus(logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z, mu, logvar\n",
    "\n",
    "# === RSSM Core ===\n",
    "class RSSMCore(nn.Module):\n",
    "    def __init__(self, action_dim, z_dim, h_dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.h_dim = h_dim\n",
    "\n",
    "        self.project_action_z = nn.Linear(z_dim + action_dim, h_dim)\n",
    "        self.gru = nn.GRUCell(h_dim, h_dim)\n",
    "\n",
    "        self.project_hidden_action = nn.Linear(h_dim + action_dim, h_dim)\n",
    "        self.prior = nn.Linear(h_dim, z_dim * 2)\n",
    "\n",
    "        self.project_hidden_obs = nn.Linear(h_dim + embed_dim, h_dim)\n",
    "        self.posterior = nn.Linear(h_dim, z_dim * 2)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, prev_z, prev_h, actions, embeddings=None, dones=None):\n",
    "        B, T, _ = actions.size()\n",
    "        h, z = prev_h, prev_z\n",
    "\n",
    "        h_seq, z_seq, prior_mean_seq, prior_std_seq = [], [], [], []\n",
    "        post_mean_seq, post_std_seq = [], []\n",
    "        # min_std = 1e-3  # can be adjusted\n",
    "\n",
    "        for t in range(T):\n",
    "            a = actions[:, t]\n",
    "            e = embeddings[:, t] if embeddings is not None else None\n",
    "\n",
    "            # Reset z if done\n",
    "            if dones is not None:\n",
    "                z = z * (1.0 - dones[:, t])\n",
    "\n",
    "            x = torch.cat([z, a], dim=-1)\n",
    "            x = self.activation(self.project_action_z(x))\n",
    "            h = self.gru(x, h)\n",
    "\n",
    "            # Prior\n",
    "            ha = torch.cat([h, a], dim=-1)\n",
    "            ha = self.activation(self.project_hidden_action(ha))\n",
    "            prior_params = self.prior(ha)\n",
    "            prior_mean, prior_logstd = torch.chunk(prior_params, 2, dim=-1)\n",
    "            prior_std = F.softplus(prior_logstd) #+ min_std\n",
    "            prior_dist = torch.distributions.Normal(prior_mean, prior_std)\n",
    "            prior_z = prior_dist.rsample()\n",
    "\n",
    "            # Posterior\n",
    "            if embeddings is not None:\n",
    "                he = torch.cat([h, e], dim=-1)\n",
    "                he = self.activation(self.project_hidden_obs(he))\n",
    "                post_params = self.posterior(he)\n",
    "                post_mean, post_logstd = torch.chunk(post_params, 2, dim=-1)\n",
    "                post_std = F.softplus(post_logstd) #+ min_std\n",
    "                post_dist = torch.distributions.Normal(post_mean, post_std)\n",
    "                post_z = post_dist.rsample()\n",
    "            else:\n",
    "                post_z = prior_z\n",
    "                post_mean, post_std = prior_mean, prior_std\n",
    "\n",
    "            z = post_z\n",
    "\n",
    "            # Collect for each timestep\n",
    "            h_seq.append(h.unsqueeze(1))\n",
    "            z_seq.append(z.unsqueeze(1))\n",
    "            prior_mean_seq.append(prior_mean.unsqueeze(1))\n",
    "            prior_std_seq.append(prior_std.unsqueeze(1))\n",
    "            post_mean_seq.append(post_mean.unsqueeze(1))\n",
    "            post_std_seq.append(post_std.unsqueeze(1))\n",
    "\n",
    "        return {\n",
    "            'h': torch.cat(h_seq, dim=1),\n",
    "            'z': torch.cat(z_seq, dim=1),\n",
    "            'prior_mean': torch.cat(prior_mean_seq, dim=1),\n",
    "            'prior_std': torch.cat(prior_std_seq, dim=1),\n",
    "            'post_mean': torch.cat(post_mean_seq, dim=1),\n",
    "            'post_std': torch.cat(post_std_seq, dim=1),\n",
    "        }\n",
    "        \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        return (\n",
    "            torch.zeros(batch_size, self.z_dim, device=device),\n",
    "            torch.zeros(batch_size, self.h_dim, device=device)\n",
    "        )\n",
    "\n",
    "    def step(self, prev_z, prev_h, action, embedding=None, done=None):\n",
    "        x = torch.cat([prev_z, action], dim=-1)\n",
    "        x = self.activation(self.project_action_z(x))\n",
    "        h = self.gru(x, prev_h)\n",
    "\n",
    "        ha = torch.cat([h, action], dim=-1)\n",
    "        ha = self.activation(self.project_hidden_action(ha))\n",
    "        prior_params = self.prior(ha)\n",
    "        prior_mean, prior_logstd = torch.chunk(prior_params, 2, dim=-1)\n",
    "        prior_std = F.softplus(prior_logstd)\n",
    "        prior_dist = torch.distributions.Normal(prior_mean, prior_std)\n",
    "        prior_z = prior_dist.rsample()\n",
    "\n",
    "        if embedding is not None:\n",
    "            he = torch.cat([h, embedding], dim=-1)\n",
    "            he = self.activation(self.project_hidden_obs(he))\n",
    "            post_params = self.posterior(he)\n",
    "            post_mean, post_logstd = torch.chunk(post_params, 2, dim=-1)\n",
    "            post_std = F.softplus(post_logstd)\n",
    "            post_dist = torch.distributions.Normal(post_mean, post_std)\n",
    "            post_z = post_dist.rsample()\n",
    "        else:\n",
    "            post_z = prior_z\n",
    "            post_mean, post_std = prior_mean, prior_std\n",
    "\n",
    "        if done is not None:\n",
    "            post_z = post_z * (1.0 - done)\n",
    "\n",
    "        return h, post_z, post_mean, post_std\n",
    "\n",
    "\n",
    "# === Pose Decoder ===\n",
    "class PoseDecoder(nn.Module):\n",
    "    def __init__(self, h_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(h_dim, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        return self.fc(h)\n",
    "\n",
    "# === Frame Decoder ===\n",
    "class FrameDecoder(nn.Module):\n",
    "    def __init__(self, h_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(h_dim, 128 * 16 * 16)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 4, 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        x = self.fc(h).view(-1, 128, 16, 16)\n",
    "        x = self.deconv(x)\n",
    "        return x\n",
    "\n",
    "# === RSSM Model ===\n",
    "class RSSMGoalDeltaPoseModel(nn.Module):\n",
    "    def __init__(self, z_dim=64, h_dim=256, action_dim=6, embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(z_dim)\n",
    "        self.rssm = RSSMCore(action_dim, z_dim, h_dim, embed_dim)\n",
    "        self.pose_decoder = PoseDecoder(h_dim)\n",
    "        self.frame_decoder = FrameDecoder(h_dim)\n",
    "        self.z_dim = z_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "    def forward(self, obs_seq, delta_pose_seq):  # obs_seq: [B, T, 1, H, W], delta_pose_seq: [B, T, 6]\n",
    "        B, T, C, H, W = obs_seq.shape\n",
    "        device = obs_seq.device\n",
    "        h = torch.zeros(B, self.h_dim, device=device)\n",
    "        z = torch.zeros(B, self.z_dim, device=device)\n",
    "\n",
    "        embeddings, mus, logvars = [], [], []\n",
    "        for t in range(T):\n",
    "            z_t, mu_t, logvar_t = self.encoder(obs_seq[:, t])\n",
    "            embeddings.append(z_t.unsqueeze(1))\n",
    "            mus.append(mu_t.unsqueeze(1))\n",
    "            logvars.append(logvar_t.unsqueeze(1))\n",
    "        embeddings = torch.cat(embeddings, dim=1)  # [B, T, z_dim]\n",
    "        mus = torch.cat(mus, dim=1)\n",
    "        logvars = torch.cat(logvars, dim=1)\n",
    "\n",
    "        rssm_out = self.rssm(z, h, delta_pose_seq, embeddings=embeddings)\n",
    "\n",
    "        pose_preds = self.pose_decoder(rssm_out['h'])  # [B, T, 6]\n",
    "        img_preds = self.frame_decoder(rssm_out['h'].reshape(-1, self.h_dim)).reshape(B, T, 1, H, W)\n",
    "\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvars - mus.pow(2) - logvars.exp(), dim=-1).mean()\n",
    "        return pose_preds, img_preds, kl_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def batched_predict_sequence(model, init_batch, inf_batch, device):\n",
    "    \"\"\"\n",
    "    Batched inference over multiple sequences (batch_size > 1)\n",
    "    - init_batch: [B, init_len, 1, H, W]\n",
    "    - inf_batch:  [B, T, 1, H, W]\n",
    "\n",
    "    Returns:\n",
    "        predicted_delta_poses: [B, T-1, 6]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    B, init_len, _, H, W = init_batch.shape\n",
    "    T = inf_batch.shape[1]  # T == inference_len\n",
    "\n",
    "    encoder = model.encoder\n",
    "    rssm = model.rssm\n",
    "    pose_decoder = model.pose_decoder\n",
    "\n",
    "    init_batch = init_batch.to(device)\n",
    "    inf_batch = inf_batch.to(device)\n",
    "\n",
    "    # --- Initialize latent state ---\n",
    "    z, h = rssm.init_hidden(B, device)\n",
    "\n",
    "    # --- Feed init images to accumulate state ---\n",
    "    init_images = init_batch.view(B * init_len, 1, H, W)\n",
    "    init_embeds, _, _ = encoder(init_images)\n",
    "    init_embeds = init_embeds.view(B, init_len, -1)\n",
    "\n",
    "    # Use zero action only during init\n",
    "    zero_action = torch.zeros(B, model.action_dim, device=device)\n",
    "    for t in range(init_len):\n",
    "        h, z, _, _ = rssm.step(z, h, zero_action, embedding=init_embeds[:, t])\n",
    "\n",
    "    # --- Predict delta poses using inference images ---\n",
    "    inf_images = inf_batch[:, :-1].reshape(B * (T - 1), 1, H, W)\n",
    "    inf_embeds, _, _ = encoder(inf_images)\n",
    "    inf_embeds = inf_embeds.view(B, T - 1, -1)\n",
    "\n",
    "    pred_delta_poses = []\n",
    "    prev_action = torch.zeros(B, model.action_dim, device=device)  # or learned init\n",
    "\n",
    "    for t in range(T - 1):\n",
    "        h, z, _, _ = rssm.step(z, h, prev_action, embedding=inf_embeds[:, t])\n",
    "        delta_pose = pose_decoder(h)  # [B, 6]\n",
    "        pred_delta_poses.append(delta_pose)\n",
    "        prev_action = delta_pose.detach()  # Use prediction as next action\n",
    "\n",
    "    pred_delta_poses = torch.stack(pred_delta_poses, dim=1)  # [B, T-1, 6]\n",
    "    return pred_delta_poses\n",
    "\n",
    "\n",
    "# === Evaluate ===\n",
    "def eval_model(model, dataloader, device, lambda_sign=2.0):\n",
    "    model.eval()\n",
    "    total_test_loss = 0.0\n",
    "    total_test_base_loss = 0.0\n",
    "    total_test_sign_loss = 0.0\n",
    "    total_test_recon_loss = 0.0\n",
    "    total_test_kl_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for obs_seq, delta_poses_seq in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            obs_seq = obs_seq.to(device)\n",
    "            delta_poses_seq = delta_poses_seq.to(device)\n",
    "\n",
    "            pose_preds, img_preds, kl_loss = model(obs_seq, delta_poses_seq)\n",
    "\n",
    "            loss_pose, base_loss, sign_loss = weighted_pose_loss(\n",
    "                pose_preds, delta_poses_seq, lambda_sign=lambda_sign, return_components=True\n",
    "            )\n",
    "            loss_recon = F.mse_loss(img_preds, obs_seq)\n",
    "            loss = 7.0 * loss_pose + 0.7 * loss_recon + 0.1 * kl_loss\n",
    "\n",
    "            total_test_loss += loss.item()\n",
    "            total_test_base_loss += base_loss.item()\n",
    "            total_test_sign_loss += sign_loss.item()\n",
    "            total_test_recon_loss += loss_recon.item()\n",
    "            total_test_kl_loss += kl_loss.item()\n",
    "\n",
    "            all_preds.append(pose_preds.cpu())\n",
    "            all_targets.append(delta_poses_seq.cpu())\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(dataloader)\n",
    "    avg_test_base_loss = total_test_base_loss / len(dataloader)\n",
    "    avg_test_sign_loss = total_test_sign_loss / len(dataloader)\n",
    "    avg_test_recon_loss = total_test_recon_loss / len(dataloader)\n",
    "    avg_test_kl_loss = total_test_kl_loss / len(dataloader)\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0)  # [N, T, 6]\n",
    "    all_targets = torch.cat(all_targets, dim=0)  # [N, T, 6]\n",
    "\n",
    "    return {\n",
    "        'avg_loss': avg_test_loss,\n",
    "        'base_loss': avg_test_base_loss,\n",
    "        'sign_loss': avg_test_sign_loss,\n",
    "        'recon_loss': avg_test_recon_loss,\n",
    "        'kl_loss': avg_test_kl_loss,\n",
    "        'preds': all_preds,\n",
    "        'targets': all_targets\n",
    "    }\n",
    "\n",
    "# === Weighted_pose_loss ===\n",
    "def weighted_pose_loss(pred, target, lambda_sign=2.0, return_components=False):\n",
    "    weights = torch.tensor([2.0, 2.0, 2.0, 3.0, 2.0, 1.0], device=pred.device)\n",
    "    \n",
    "    weighted_pred = pred * weights\n",
    "    weighted_target = target * weights\n",
    "    base_loss = F.smooth_l1_loss(weighted_pred, weighted_target)\n",
    "\n",
    "    # sign consistency loss\n",
    "    sign_penalty = torch.relu(-pred * target)  # penalize different signs\n",
    "    sign_loss = (sign_penalty * weights).mean()\n",
    "\n",
    "    total_loss = base_loss + lambda_sign * sign_loss\n",
    "    \n",
    "    if return_components:\n",
    "        return total_loss, base_loss, sign_loss\n",
    "    else:\n",
    "        return total_loss\n",
    "        \n",
    "# === Train Model ===\n",
    "def train_model(csv_path, train_dirs, test_dirs, image_size=(256, 256), batch_size=8, epochs=20, lr=1e-4):\n",
    "    loss_log_path = 'RSSM_6_losses.csv'\n",
    "    with open(loss_log_path, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            'epoch',\n",
    "            'train_loss', 'train_base_loss', 'train_sign_loss', 'train_recon_loss', 'train_kl_loss',\n",
    "            'test_loss',\n",
    "            'acc_tx', 'acc_ty', 'acc_tz', 'acc_rx', 'acc_ry', 'acc_rz', 'overall_acc'\n",
    "        ])\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_dataset = SequenceUltrasoundDataset(csv_path, train_dirs, sequence_length=15, image_size=image_size)\n",
    "    test_dataset = InferenceUltrasoundDatasetNoGoal(csv_path, test_dirs, init_len=5, inf_len=2, image_size=image_size)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    model = RSSMGoalDeltaPoseModel(h_dim=256).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_test_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ==== Training ====\n",
    "        model.train()\n",
    "        total_train_loss = total_train_base_loss = total_train_sign_loss = 0.0\n",
    "        total_train_recon_loss = total_train_kl_loss = 0.0\n",
    "\n",
    "        for obs_seq, delta_poses_seq in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "            obs_seq, delta_poses_seq = obs_seq.to(device), delta_poses_seq.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pose_preds, img_preds, kl_loss = model(obs_seq, delta_poses_seq)\n",
    "\n",
    "            loss_pose, base_loss, sign_loss = weighted_pose_loss(pose_preds, delta_poses_seq, lambda_sign=2.0, return_components=True)\n",
    "            loss_recon = F.mse_loss(img_preds, obs_seq)\n",
    "            loss = 7.0 * loss_pose + 0.7 * loss_recon + 0.1 * kl_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            total_train_base_loss += base_loss.item()\n",
    "            total_train_sign_loss += sign_loss.item()\n",
    "            total_train_recon_loss += loss_recon.item()\n",
    "            total_train_kl_loss += kl_loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_train_base_loss = total_train_base_loss / len(train_loader)\n",
    "        avg_train_sign_loss = total_train_sign_loss / len(train_loader)\n",
    "        avg_train_recon_loss = total_train_recon_loss / len(train_loader)\n",
    "        avg_train_kl_loss = total_train_kl_loss / len(train_loader)\n",
    "\n",
    "        # ==== Testing ====\n",
    "        model.eval()\n",
    "        total_test_loss = 0.0\n",
    "        all_test_pred = []\n",
    "        all_test_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=f\"Epoch {epoch+1} Eval\"):\n",
    "                # batch keys: 'sequence_name', 'image_sequence', 'inference_images', 'ground_truth_delta_poses'\n",
    "                init_images = batch['init_images'].to(device)           # [B, init_len, 1, H, W]\n",
    "                inf_images = batch['inference_images'].to(device)       # [B, T, 1, H, W]\n",
    "                target_delta_pose = batch['ground_truth_delta_poses'].to(device)  # [B, T-1, 6]\n",
    "\n",
    "                pred_delta_pose = batched_predict_sequence(model, init_images, inf_images, device)\n",
    "\n",
    "                loss = weighted_pose_loss(pred_delta_pose, target_delta_pose)\n",
    "\n",
    "                total_test_loss += loss.item() * 1  # batch=1\n",
    "                all_test_pred.append(pred_delta_pose.cpu().numpy())\n",
    "                all_test_true.append(target_delta_pose.cpu().numpy())\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(test_loader)\n",
    "\n",
    "        # ==== Accuracy Evaluation ====\n",
    "        all_test_pred_arr = np.concatenate(all_test_pred, axis=0).astype(np.float32).reshape(-1, 6)\n",
    "        all_test_true_arr = np.concatenate(all_test_true, axis=0).astype(np.float32).reshape(-1, 6)\n",
    "\n",
    "        pred = all_test_pred_arr  # shape: [N, 6]\n",
    "        true = all_test_true_arr\n",
    "        epsilon = 1e-6\n",
    "        within_bounds = (pred >= 0.5 * (true + epsilon)) & (pred <= 1.5 * (true + epsilon))\n",
    "        true_zero = np.abs(true) < epsilon\n",
    "        pred_zero = np.abs(pred) < epsilon\n",
    "        zero_match = true_zero & pred_zero\n",
    "        correct_mask = within_bounds | zero_match\n",
    "\n",
    "        component_names = ['tx', 'ty', 'tz', 'rx', 'ry', 'rz']\n",
    "        component_accuracies = {\n",
    "            name: correct_mask[:, i].mean()\n",
    "            for i, name in enumerate(component_names)\n",
    "        }\n",
    "        overall_accuracy = np.all(correct_mask, axis=1).mean()\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_test_loss < best_test_loss:\n",
    "            best_test_loss = avg_test_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"✅ Best model saved at epoch {epoch+1} with test_loss: {avg_test_loss:.6f}\")\n",
    "        \n",
    "        # Save test results CSV\n",
    "        ratio = (pred + epsilon) / (true + epsilon)\n",
    "        df_test_results = pd.DataFrame({\n",
    "            **{f'pred_{name}': pred[:, i].flatten() for i, name in enumerate(component_names)},\n",
    "            **{f'true_{name}': true[:, i].flatten() for i, name in enumerate(component_names)},\n",
    "            **{f'ratio_{name}': ratio[:, i].flatten() for i, name in enumerate(component_names)},\n",
    "        })\n",
    "        df_test_results.to_csv(f'RSSM_6_test_pred_true_epoch_{epoch+1}.csv', index=False)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f}\")\n",
    "        for name in component_names:\n",
    "            print(f\"  {name} acc: {component_accuracies[name]:.4f}\")\n",
    "        print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "        \n",
    "        # Save model and log\n",
    "        #torch.save(model.state_dict(), f'RSSM_6_model_epoch_{epoch+1}.pth')\n",
    "        with open(loss_log_path, mode='a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                epoch + 1,\n",
    "                avg_train_loss, avg_train_base_loss, avg_train_sign_loss, avg_train_recon_loss, avg_train_kl_loss,\n",
    "                avg_test_loss,\n",
    "                component_accuracies['tx'], component_accuracies['ty'], component_accuracies['tz'],\n",
    "                component_accuracies['rx'], component_accuracies['ry'], component_accuracies['rz'],\n",
    "                overall_accuracy\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04086aa2-9e59-44e5-a38c-1e6ea4c30a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|████████████████████████████████████████████████████████████████| 81/81 [06:31<00:00,  4.83s/it]\n",
      "Epoch 1 Eval: 100%|████████████████████████████████████████████████████████████████████| 36/36 [00:57<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 1 with test_loss: 0.372701\n",
      "[Epoch 1] Train Loss: 6.6004 | Test Loss: 0.3727\n",
      "  tx acc: 0.0243\n",
      "  ty acc: 0.0261\n",
      "  tz acc: 0.0226\n",
      "  rx acc: 0.0209\n",
      "  ry acc: 0.0191\n",
      "  rz acc: 0.0365\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|████████████████████████████████████████████████████████████████| 81/81 [06:49<00:00,  5.06s/it]\n",
      "Epoch 2 Eval: 100%|████████████████████████████████████████████████████████████████████| 36/36 [01:03<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 3.5465 | Test Loss: 0.4063\n",
      "  tx acc: 0.0417\n",
      "  ty acc: 0.1530\n",
      "  tz acc: 0.0017\n",
      "  rx acc: 0.0783\n",
      "  ry acc: 0.0539\n",
      "  rz acc: 0.0957\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|████████████████████████████████████████████████████████████████| 81/81 [06:47<00:00,  5.03s/it]\n",
      "Epoch 3 Eval: 100%|████████████████████████████████████████████████████████████████████| 36/36 [00:58<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 1.6639 | Test Loss: 0.3754\n",
      "  tx acc: 0.0157\n",
      "  ty acc: 0.0000\n",
      "  tz acc: 0.0104\n",
      "  rx acc: 0.0000\n",
      "  ry acc: 0.1252\n",
      "  rz acc: 0.1443\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|████████████████████████████████████████████████████████████████| 81/81 [06:43<00:00,  4.98s/it]\n",
      "Epoch 4 Eval: 100%|████████████████████████████████████████████████████████████████████| 36/36 [01:00<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 1.1321 | Test Loss: 0.3852\n",
      "  tx acc: 0.0991\n",
      "  ty acc: 0.0226\n",
      "  tz acc: 0.0348\n",
      "  rx acc: 0.0470\n",
      "  ry acc: 0.0000\n",
      "  rz acc: 0.0000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|████████████████████████████████████████████████████████████████| 81/81 [06:41<00:00,  4.95s/it]\n",
      "Epoch 5 Eval: 100%|████████████████████████████████████████████████████████████████████| 36/36 [00:59<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 0.8757 | Test Loss: 0.3816\n",
      "  tx acc: 0.0017\n",
      "  ty acc: 0.0383\n",
      "  tz acc: 0.0000\n",
      "  rx acc: 0.0730\n",
      "  ry acc: 0.0000\n",
      "  rz acc: 0.0000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|████████████████████████████████████████████████████████████████| 81/81 [06:31<00:00,  4.84s/it]\n",
      "Epoch 6 Eval: 100%|████████████████████████████████████████████████████████████████████| 36/36 [00:57<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 6 with test_loss: 0.367540\n",
      "[Epoch 6] Train Loss: 0.6574 | Test Loss: 0.3675\n",
      "  tx acc: 0.0104\n",
      "  ty acc: 0.0017\n",
      "  tz acc: 0.0365\n",
      "  rx acc: 0.0017\n",
      "  ry acc: 0.0035\n",
      "  rz acc: 0.0000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|████████████████████████████████████████████████████████████████| 81/81 [06:33<00:00,  4.86s/it]\n",
      "Epoch 7 Eval: 100%|████████████████████████████████████████████████████████████████████| 36/36 [00:59<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 0.5035 | Test Loss: 0.3766\n",
      "  tx acc: 0.0000\n",
      "  ty acc: 0.0000\n",
      "  tz acc: 0.1078\n",
      "  rx acc: 0.0000\n",
      "  ry acc: 0.1026\n",
      "  rz acc: 0.0052\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|████████████████████████████████████████████████████████████████| 81/81 [06:28<00:00,  4.80s/it]\n",
      "Epoch 8 Eval: 100%|████████████████████████████████████████████████████████████████████| 36/36 [00:57<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 0.4106 | Test Loss: 0.3703\n",
      "  tx acc: 0.0000\n",
      "  ty acc: 0.0000\n",
      "  tz acc: 0.0000\n",
      "  rx acc: 0.0452\n",
      "  ry acc: 0.0296\n",
      "  rz acc: 0.0000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|████████████████████████████████████████████████████████████████| 81/81 [06:33<00:00,  4.85s/it]\n",
      "Epoch 9 Eval: 100%|████████████████████████████████████████████████████████████████████| 36/36 [00:58<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 0.3396 | Test Loss: 0.3707\n",
      "  tx acc: 0.0017\n",
      "  ty acc: 0.0087\n",
      "  tz acc: 0.1026\n",
      "  rx acc: 0.0713\n",
      "  ry acc: 0.0261\n",
      "  rz acc: 0.0765\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|███████████████████████████████████████████████████████████████| 81/81 [06:35<00:00,  4.88s/it]\n",
      "Epoch 10 Eval: 100%|███████████████████████████████████████████████████████████████████| 36/36 [00:57<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 10 with test_loss: 0.361130\n",
      "[Epoch 10] Train Loss: 0.2846 | Test Loss: 0.3611\n",
      "  tx acc: 0.0035\n",
      "  ty acc: 0.0052\n",
      "  tz acc: 0.1183\n",
      "  rx acc: 0.0000\n",
      "  ry acc: 0.0070\n",
      "  rz acc: 0.0174\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 100%|███████████████████████████████████████████████████████████████| 81/81 [06:34<00:00,  4.87s/it]\n",
      "Epoch 11 Eval: 100%|███████████████████████████████████████████████████████████████████| 36/36 [01:00<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 0.2472 | Test Loss: 0.3620\n",
      "  tx acc: 0.0000\n",
      "  ty acc: 0.0017\n",
      "  tz acc: 0.0035\n",
      "  rx acc: 0.0000\n",
      "  ry acc: 0.0052\n",
      "  rz acc: 0.0000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training: 100%|███████████████████████████████████████████████████████████████| 81/81 [06:37<00:00,  4.90s/it]\n",
      "Epoch 12 Eval: 100%|███████████████████████████████████████████████████████████████████| 36/36 [00:58<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 0.2152 | Test Loss: 0.3627\n",
      "  tx acc: 0.0017\n",
      "  ty acc: 0.0261\n",
      "  tz acc: 0.0435\n",
      "  rx acc: 0.0000\n",
      "  ry acc: 0.0243\n",
      "  rz acc: 0.0000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training: 100%|███████████████████████████████████████████████████████████████| 81/81 [06:44<00:00,  4.99s/it]\n",
      "Epoch 13 Eval: 100%|███████████████████████████████████████████████████████████████████| 36/36 [00:58<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 0.1887 | Test Loss: 0.3780\n",
      "  tx acc: 0.0400\n",
      "  ty acc: 0.0296\n",
      "  tz acc: 0.0487\n",
      "  rx acc: 0.0887\n",
      "  ry acc: 0.0591\n",
      "  rz acc: 0.0000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training: 100%|███████████████████████████████████████████████████████████████| 81/81 [06:40<00:00,  4.94s/it]\n",
      "Epoch 14 Eval: 100%|███████████████████████████████████████████████████████████████████| 36/36 [00:59<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 0.1682 | Test Loss: 0.3621\n",
      "  tx acc: 0.0365\n",
      "  ty acc: 0.0139\n",
      "  tz acc: 0.0817\n",
      "  rx acc: 0.0139\n",
      "  ry acc: 0.0017\n",
      "  rz acc: 0.0052\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training: 100%|███████████████████████████████████████████████████████████████| 81/81 [06:49<00:00,  5.05s/it]\n",
      "Epoch 15 Eval: 100%|███████████████████████████████████████████████████████████████████| 36/36 [01:02<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 15 with test_loss: 0.356721\n",
      "[Epoch 15] Train Loss: 0.1529 | Test Loss: 0.3567\n",
      "  tx acc: 0.0000\n",
      "  ty acc: 0.0122\n",
      "  tz acc: 0.0104\n",
      "  rx acc: 0.0000\n",
      "  ry acc: 0.0104\n",
      "  rz acc: 0.0087\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training: 100%|███████████████████████████████████████████████████████████████| 81/81 [06:47<00:00,  5.03s/it]\n",
      "Epoch 16 Eval: 100%|███████████████████████████████████████████████████████████████████| 36/36 [00:56<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 0.1395 | Test Loss: 0.3716\n",
      "  tx acc: 0.0226\n",
      "  ty acc: 0.0417\n",
      "  tz acc: 0.0035\n",
      "  rx acc: 0.0765\n",
      "  ry acc: 0.0296\n",
      "  rz acc: 0.0000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training: 100%|███████████████████████████████████████████████████████████████| 81/81 [06:30<00:00,  4.82s/it]\n",
      "Epoch 17 Eval: 100%|███████████████████████████████████████████████████████████████████| 36/36 [00:57<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 0.1308 | Test Loss: 0.3612\n",
      "  tx acc: 0.0000\n",
      "  ty acc: 0.0139\n",
      "  tz acc: 0.0191\n",
      "  rx acc: 0.0000\n",
      "  ry acc: 0.0000\n",
      "  rz acc: 0.0000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training: 100%|███████████████████████████████████████████████████████████████| 81/81 [06:29<00:00,  4.81s/it]\n",
      "Epoch 18 Eval: 100%|███████████████████████████████████████████████████████████████████| 36/36 [00:56<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 0.1204 | Test Loss: 0.3592\n",
      "  tx acc: 0.0174\n",
      "  ty acc: 0.0000\n",
      "  tz acc: 0.0035\n",
      "  rx acc: 0.0000\n",
      "  ry acc: 0.0000\n",
      "  rz acc: 0.0000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training: 100%|███████████████████████████████████████████████████████████████| 81/81 [06:34<00:00,  4.87s/it]\n",
      "Epoch 19 Eval: 100%|███████████████████████████████████████████████████████████████████| 36/36 [00:57<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 0.1114 | Test Loss: 0.3633\n",
      "  tx acc: 0.0157\n",
      "  ty acc: 0.0452\n",
      "  tz acc: 0.0052\n",
      "  rx acc: 0.0139\n",
      "  ry acc: 0.0000\n",
      "  rz acc: 0.0000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training: 100%|███████████████████████████████████████████████████████████████| 81/81 [06:40<00:00,  4.95s/it]\n",
      "Epoch 20 Eval: 100%|███████████████████████████████████████████████████████████████████| 36/36 [01:00<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train Loss: 0.1055 | Test Loss: 0.3593\n",
      "  tx acc: 0.0000\n",
      "  ty acc: 0.0070\n",
      "  tz acc: 0.0000\n",
      "  rx acc: 0.0000\n",
      "  ry acc: 0.0087\n",
      "  rz acc: 0.0000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Run ===\n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        csv_path=\"poses_combined.csv\",\n",
    "        train_dirs=train_dirs,\n",
    "        test_dirs=test_dirs,\n",
    "        epochs=20,\n",
    "        batch_size=16,\n",
    "        lr=1e-4,\n",
    "        image_size=(256, 256)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389c889-f3c5-4ed9-8f44-8e28a1c418f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bmilab)",
   "language": "python",
   "name": "bmilab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
