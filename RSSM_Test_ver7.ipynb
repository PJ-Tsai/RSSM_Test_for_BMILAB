{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddee535e-59b8-4375-83d0-dc009340efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSSM-based Delta Pose Predictor for Ultrasound Images\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import csv\n",
    "import cv2\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3070b1-33c4-436e-852e-ea3ee01462f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Data Root\n",
    "data_root = '.'  # /path/to/data\n",
    "\n",
    "# Set train/test folder names\n",
    "train_dirs = {\n",
    "    \"frames_0513_06\",# \"frames_0513_07\", \"frames_0513_08\", \"frames_0513_09\",\n",
    "    \"frames_0513_11\", \"frames_0513_12\",# \"frames_0513_13\", \"frames_0513_14\", \"frames_0513_15\",\n",
    "    \"frames_0513_16\", \"frames_0513_18\",# \"frames_0513_19\", \"frames_0513_20\",\n",
    "    \"frames_0513_22\", \"frames_0513_24\",# \"frames_0513_22\", \"frames_0513_23\", \"frames_0513_24\", \"frames_0513_25\", \"frames_0513_26\"\n",
    "}\n",
    "\n",
    "test_dirs = {\n",
    "    \"frames_0513_01\"#\"frames_0513_01\", \"frames_0513_02\", \"frames_0513_03\", \"frames_0513_04\", \"frames_0513_05\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c617969d-12ba-4211-81a2-9ae27de1769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Combine CSVs ============\n",
    "def combine_pose_csvs_with_foldername(root_folder, output_csv=\"poses_combined.csv\"):\n",
    "    all_data = []\n",
    "\n",
    "    for file in sorted(os.listdir(root_folder)):\n",
    "        if not file.endswith(\"_final_data.csv\"):\n",
    "            continue\n",
    "\n",
    "        csv_path = os.path.join(root_folder, file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # ex: 0513_01_final_data.csv → frames_0513_01\n",
    "        folder_name = \"frames_\" + file.replace(\"_final_data.csv\", \"\")\n",
    "\n",
    "        # Update Filename Column: → frames_0513_01/frame_0000.png\n",
    "        df[\"Filename\"] = df[\"Filename\"].apply(lambda x: f\"{folder_name}/{x}\")\n",
    "        all_data.append(df)\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"⚠️ No Valid File Found\")\n",
    "        return\n",
    "\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    combined_df.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Saved Combined CSV to：{output_csv}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02618978-809d-42b2-b1dc-6a74c16aec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved Combined CSV to：poses_combined.csv\n"
     ]
    }
   ],
   "source": [
    "combine_pose_csvs_with_foldername(data_root, \"poses_combined.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78d5315-6153-47e3-9dcb-6ff41c5d913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inference Ultrasound Dataset No Goal ===\n",
    "class InferenceUltrasoundDatasetNoGoal(Dataset):\n",
    "    def __init__(self, csv_path, root_dirs, init_len=5, inf_len=2, image_size=(256, 256)):\n",
    "        self.samples = []\n",
    "        self.inf_len = inf_len\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df['folder'] = df['Filename'].apply(lambda x: x.split('/')[0])\n",
    "        df = df.rename(columns={\n",
    "            'Filename': 'img_path',\n",
    "            'X (mm)': 'tx', 'Y (mm)': 'ty', 'Z (mm)': 'tz',\n",
    "            'Roll (deg)': 'rx', 'Pitch (deg)': 'ry', 'Yaw (deg)': 'rz'\n",
    "        })\n",
    "\n",
    "        for dir_ in root_dirs:\n",
    "            group = df[df['folder'] == dir_].sort_values('img_path').reset_index(drop=True)\n",
    "            frames = group.to_dict('records')\n",
    "            num_frames = len(frames)\n",
    "            if num_frames <= init_len + inf_len:\n",
    "                continue\n",
    "\n",
    "            # generate (init_seq, inf_seq) pair\n",
    "            for start_idx in range(0, num_frames - init_len - inf_len + 1):\n",
    "                init_seq = frames[start_idx : start_idx + init_len]\n",
    "                inf_seq = frames[start_idx + init_len : start_idx + init_len + inf_len]\n",
    "                sample = {\n",
    "                    'init_sequence': init_seq,\n",
    "                    'inference_sequence': inf_seq,\n",
    "                    'sequence_name': dir_\n",
    "                }\n",
    "                self.samples.append(sample)\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _load_image(self, img_path):\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Cannot read image: {img_path}\")\n",
    "        return self.transform(img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "\n",
    "        init_imgs = [self._load_image(x['img_path']) for x in item['init_sequence']]\n",
    "        inf_imgs = [self._load_image(x['img_path']) for x in item['inference_sequence']]\n",
    "\n",
    "        inf_poses = [\n",
    "            np.array([\n",
    "                x['tx'], x['ty'], x['tz'],\n",
    "                x['rx'], x['ry'], x['rz']\n",
    "            ], dtype=np.float32)\n",
    "            for x in item['inference_sequence']\n",
    "        ]\n",
    "\n",
    "        delta_poses = np.diff(np.stack(inf_poses, axis=0), axis=0)  # [T-1, 6]\n",
    "\n",
    "        return {\n",
    "            'sequence_name': item['sequence_name'],\n",
    "            'init_images': torch.stack(init_imgs),                   # [init_len, 1, H, W]\n",
    "            'inference_images': torch.stack(inf_imgs),               # [T, 1, H, W]\n",
    "            'ground_truth_delta_poses': torch.tensor(delta_poses, dtype=torch.float32),  # [T-1, 6]\n",
    "        }\n",
    "\n",
    "# === Encoder ===\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 4, stride=2, padding=1), nn.InstanceNorm2d(32), nn.ReLU(),  # 256→128\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1), nn.InstanceNorm2d(64), nn.ReLU(),  # 128→64\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1), nn.InstanceNorm2d(128), nn.ReLU(),  # 64→32\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1), nn.InstanceNorm2d(256), nn.ReLU()  # 32→16\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_mu = nn.Linear(256 * 16 * 16, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(256 * 16 * 16, latent_dim)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        std = F.softplus(logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z, mu, logvar\n",
    "\n",
    "# === RSSM Core ===\n",
    "class RSSMCore(nn.Module):\n",
    "    def __init__(self, action_dim, z_dim, h_dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.h_dim = h_dim\n",
    "\n",
    "        self.project_action_z = nn.Linear(z_dim + action_dim, h_dim)\n",
    "        self.gru = nn.GRUCell(h_dim, h_dim)\n",
    "\n",
    "        self.project_hidden_action = nn.Linear(h_dim + action_dim, h_dim)\n",
    "        self.prior = nn.Linear(h_dim, z_dim * 2)\n",
    "\n",
    "        self.project_hidden_obs = nn.Linear(h_dim + embed_dim, h_dim)\n",
    "        self.posterior = nn.Linear(h_dim, z_dim * 2)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, prev_z, prev_h, actions, embeddings=None, dones=None):\n",
    "        B, T, _ = actions.size()\n",
    "        h, z = prev_h, prev_z\n",
    "\n",
    "        h_seq, z_seq, prior_mean_seq, prior_std_seq = [], [], [], []\n",
    "        post_mean_seq, post_std_seq = [], []\n",
    "        # min_std = 1e-3  # can be adjusted\n",
    "\n",
    "        for t in range(T):\n",
    "            a = actions[:, t]\n",
    "            e = embeddings[:, t] if embeddings is not None else None\n",
    "\n",
    "            # Reset z if done\n",
    "            if dones is not None:\n",
    "                z = z * (1.0 - dones[:, t])\n",
    "\n",
    "            x = torch.cat([z, a], dim=-1)\n",
    "            x = self.activation(self.project_action_z(x))\n",
    "            h = self.gru(x, h)\n",
    "\n",
    "            # Prior\n",
    "            ha = torch.cat([h, a], dim=-1)\n",
    "            ha = self.activation(self.project_hidden_action(ha))\n",
    "            prior_params = self.prior(ha)\n",
    "            prior_mean, prior_logstd = torch.chunk(prior_params, 2, dim=-1)\n",
    "            prior_std = F.softplus(prior_logstd) #+ min_std\n",
    "            prior_dist = torch.distributions.Normal(prior_mean, prior_std)\n",
    "            prior_z = prior_dist.rsample()\n",
    "\n",
    "            # Posterior\n",
    "            if embeddings is not None:\n",
    "                he = torch.cat([h, e], dim=-1)\n",
    "                he = self.activation(self.project_hidden_obs(he))\n",
    "                post_params = self.posterior(he)\n",
    "                post_mean, post_logstd = torch.chunk(post_params, 2, dim=-1)\n",
    "                post_std = F.softplus(post_logstd) #+ min_std\n",
    "                post_dist = torch.distributions.Normal(post_mean, post_std)\n",
    "                post_z = post_dist.rsample()\n",
    "            else:\n",
    "                post_z = prior_z\n",
    "                post_mean, post_std = prior_mean, prior_std\n",
    "\n",
    "            z = post_z\n",
    "\n",
    "            # Collect for each timestep\n",
    "            h_seq.append(h.unsqueeze(1))\n",
    "            z_seq.append(z.unsqueeze(1))\n",
    "            prior_mean_seq.append(prior_mean.unsqueeze(1))\n",
    "            prior_std_seq.append(prior_std.unsqueeze(1))\n",
    "            post_mean_seq.append(post_mean.unsqueeze(1))\n",
    "            post_std_seq.append(post_std.unsqueeze(1))\n",
    "\n",
    "        return {\n",
    "            'h': torch.cat(h_seq, dim=1),\n",
    "            'z': torch.cat(z_seq, dim=1),\n",
    "            'prior_mean': torch.cat(prior_mean_seq, dim=1),\n",
    "            'prior_std': torch.cat(prior_std_seq, dim=1),\n",
    "            'post_mean': torch.cat(post_mean_seq, dim=1),\n",
    "            'post_std': torch.cat(post_std_seq, dim=1),\n",
    "        }\n",
    "        \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        return (\n",
    "            torch.zeros(batch_size, self.z_dim, device=device),\n",
    "            torch.zeros(batch_size, self.h_dim, device=device)\n",
    "        )\n",
    "\n",
    "    def step(self, prev_z, prev_h, action, embedding=None, done=None):\n",
    "        x = torch.cat([prev_z, action], dim=-1)\n",
    "        x = self.activation(self.project_action_z(x))\n",
    "        h = self.gru(x, prev_h)\n",
    "\n",
    "        ha = torch.cat([h, action], dim=-1)\n",
    "        ha = self.activation(self.project_hidden_action(ha))\n",
    "        prior_params = self.prior(ha)\n",
    "        prior_mean, prior_logstd = torch.chunk(prior_params, 2, dim=-1)\n",
    "        prior_std = F.softplus(prior_logstd)\n",
    "        prior_dist = torch.distributions.Normal(prior_mean, prior_std)\n",
    "        prior_z = prior_dist.rsample()\n",
    "\n",
    "        if embedding is not None:\n",
    "            he = torch.cat([h, embedding], dim=-1)\n",
    "            he = self.activation(self.project_hidden_obs(he))\n",
    "            post_params = self.posterior(he)\n",
    "            post_mean, post_logstd = torch.chunk(post_params, 2, dim=-1)\n",
    "            post_std = F.softplus(post_logstd)\n",
    "            post_dist = torch.distributions.Normal(post_mean, post_std)\n",
    "            post_z = post_dist.rsample()\n",
    "        else:\n",
    "            post_z = prior_z\n",
    "            post_mean, post_std = prior_mean, prior_std\n",
    "\n",
    "        if done is not None:\n",
    "            post_z = post_z * (1.0 - done)\n",
    "\n",
    "        return h, post_z, post_mean, post_std\n",
    "\n",
    "\n",
    "# === Pose Decoder ===\n",
    "class PoseDecoder(nn.Module):\n",
    "    def __init__(self, h_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(h_dim, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        return self.fc(h)\n",
    "\n",
    "# === Frame Decoder ===\n",
    "class FrameDecoder(nn.Module):\n",
    "    def __init__(self, h_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(h_dim, 128 * 16 * 16)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 4, 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        x = self.fc(h).view(-1, 128, 16, 16)\n",
    "        x = self.deconv(x)\n",
    "        return x\n",
    "\n",
    "class RSSMGoalDeltaPoseModel(nn.Module):\n",
    "    def __init__(self, z_dim=64, h_dim=256, action_dim=6, embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(z_dim)\n",
    "        self.rssm = RSSMCore(action_dim, z_dim, h_dim, embed_dim)\n",
    "        self.pose_decoder = PoseDecoder(h_dim)\n",
    "        self.frame_decoder = FrameDecoder(h_dim)\n",
    "        self.z_dim = z_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "    def forward(self, init_imgs, inf_imgs):  \n",
    "        \"\"\"\n",
    "        init_imgs: [B, init_len, 1, H, W]\n",
    "        inf_imgs:  [B, T, 1, H, W]\n",
    "        \"\"\"\n",
    "        B, init_len, _, H, W = init_imgs.shape\n",
    "        T = inf_imgs.shape[1]\n",
    "        device = init_imgs.device\n",
    "\n",
    "        z, h = self.rssm.init_hidden(B, device)\n",
    "\n",
    "        # --- Encode and initialize with init sequence ---\n",
    "        init_embeds, _, _ = self.encoder(init_imgs.view(B * init_len, 1, H, W))\n",
    "        init_embeds = init_embeds.view(B, init_len, -1)\n",
    "\n",
    "        zero_action = torch.zeros(B, self.action_dim, device=device)\n",
    "        for t in range(init_len):\n",
    "            h, z, _, _ = self.rssm.step(z, h, zero_action, embedding=init_embeds[:, t])\n",
    "\n",
    "        # --- Encode inference images ---\n",
    "        inf_embeds, mus, logvars = [], [], []\n",
    "        for t in range(T):\n",
    "            embed, mu, logvar = self.encoder(inf_imgs[:, t])\n",
    "            inf_embeds.append(embed.unsqueeze(1))\n",
    "            mus.append(mu.unsqueeze(1))\n",
    "            logvars.append(logvar.unsqueeze(1))\n",
    "\n",
    "        inf_embeds = torch.cat(inf_embeds, dim=1)  # [B, T, z_dim]\n",
    "        mus = torch.cat(mus, dim=1)\n",
    "        logvars = torch.cat(logvars, dim=1)\n",
    "\n",
    "        # --- Rollout using inference embeddings ---\n",
    "        pred_delta_poses = []\n",
    "        recon_imgs = []\n",
    "        prev_action = torch.zeros(B, self.action_dim, device=device)\n",
    "\n",
    "        for t in range(T):\n",
    "            h, z, _, _ = self.rssm.step(z, h, prev_action, embedding=inf_embeds[:, t])\n",
    "            delta_pose = self.pose_decoder(h)       # [B, 6]\n",
    "            recon_img = self.frame_decoder(h)       # [B, 1, H, W]\n",
    "            pred_delta_poses.append(delta_pose)\n",
    "            recon_imgs.append(recon_img)\n",
    "            prev_action = delta_pose.detach()\n",
    "\n",
    "        pred_delta_poses = torch.stack(pred_delta_poses, dim=1)  # [B, T, 6]\n",
    "        recon_imgs = torch.stack(recon_imgs, dim=1)              # [B, T, 1, H, W]\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvars - mus.pow(2) - logvars.exp(), dim=-1).mean()\n",
    "\n",
    "        return pred_delta_poses, recon_imgs, kl_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def batched_predict_sequence(model, init_batch, inf_batch, device):\n",
    "    \"\"\"\n",
    "    Batched inference over multiple sequences (batch_size > 1)\n",
    "    - init_batch: [B, init_len, 1, H, W]\n",
    "    - inf_batch:  [B, T, 1, H, W]\n",
    "\n",
    "    Returns:\n",
    "        predicted_delta_poses: [B, T-1, 6]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    B, init_len, _, H, W = init_batch.shape\n",
    "    T = inf_batch.shape[1]  # T == inference_len\n",
    "\n",
    "    encoder = model.encoder\n",
    "    rssm = model.rssm\n",
    "    pose_decoder = model.pose_decoder\n",
    "\n",
    "    init_batch = init_batch.to(device)\n",
    "    inf_batch = inf_batch.to(device)\n",
    "\n",
    "    # --- Initialize latent state ---\n",
    "    z, h = rssm.init_hidden(B, device)\n",
    "\n",
    "    # --- Feed init images to accumulate state ---\n",
    "    init_images = init_batch.view(B * init_len, 1, H, W)\n",
    "    init_embeds, _, _ = encoder(init_images)\n",
    "    init_embeds = init_embeds.view(B, init_len, -1)\n",
    "\n",
    "    # Use zero action only during init\n",
    "    zero_action = torch.zeros(B, model.action_dim, device=device)\n",
    "    for t in range(init_len):\n",
    "        h, z, _, _ = rssm.step(z, h, zero_action, embedding=init_embeds[:, t])\n",
    "\n",
    "    # --- Predict delta poses using inference images ---\n",
    "    inf_images = inf_batch[:, :-1].reshape(B * (T - 1), 1, H, W)\n",
    "    inf_embeds, _, _ = encoder(inf_images)\n",
    "    inf_embeds = inf_embeds.view(B, T - 1, -1)\n",
    "\n",
    "    pred_delta_poses = []\n",
    "    prev_action = torch.zeros(B, model.action_dim, device=device)  # or learned init\n",
    "\n",
    "    for t in range(T - 1):\n",
    "        h, z, _, _ = rssm.step(z, h, prev_action, embedding=inf_embeds[:, t])\n",
    "        delta_pose = pose_decoder(h)  # [B, 6]\n",
    "        pred_delta_poses.append(delta_pose)\n",
    "        prev_action = delta_pose.detach()  # Use prediction as next action\n",
    "\n",
    "    pred_delta_poses = torch.stack(pred_delta_poses, dim=1)  # [B, T-1, 6]\n",
    "    return pred_delta_poses\n",
    "\n",
    "# === Weighted_pose_loss ===\n",
    "def weighted_pose_loss(pred, target, lambda_sign=2.0, return_components=False):\n",
    "    weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0], device=pred.device)\n",
    "\n",
    "    scale_factor=500.0\n",
    "    weighted_pred = pred * weights * scale_factor\n",
    "    weighted_target = target * weights * scale_factor\n",
    "    base_loss = F.smooth_l1_loss(weighted_pred, weighted_target)\n",
    "\n",
    "    # sign consistency loss\n",
    "    sign_penalty = torch.relu(-pred * target)  # penalize different signs\n",
    "    sign_loss = (sign_penalty * weights).mean()\n",
    "    sign_loss *= lambda_sign\n",
    "\n",
    "    total_loss = base_loss + sign_loss\n",
    "    \n",
    "    if return_components:\n",
    "        return total_loss, base_loss, sign_loss\n",
    "    else:\n",
    "        return total_loss\n",
    "        \n",
    "# === Train Model ===\n",
    "def train_model(csv_path, train_dirs, test_dirs, image_size=(256, 256), batch_size=8, epochs=20, lr=1e-4):\n",
    "    loss_log_path = 'RSSM_7_4_losses.csv'\n",
    "    with open(loss_log_path, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            'epoch',\n",
    "            'train_loss', 'train_base_loss', 'train_sign_loss', 'train_recon_loss', 'train_kl_loss',\n",
    "            'test_loss',\n",
    "            'acc_tx', 'acc_ty', 'acc_tz', 'acc_rx', 'acc_ry', 'acc_rz', 'overall_acc'\n",
    "        ])\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_dataset = InferenceUltrasoundDatasetNoGoal(csv_path, train_dirs, init_len=10, inf_len=2, image_size=image_size)\n",
    "    test_dataset = InferenceUltrasoundDatasetNoGoal(csv_path, test_dirs, init_len=10, inf_len=2, image_size=image_size)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    model = RSSMGoalDeltaPoseModel(h_dim=256).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_train_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ==== Training ====\n",
    "        model.train()\n",
    "        total_train_loss = total_train_base_loss = total_train_sign_loss = 0.0\n",
    "        total_train_recon_loss = total_train_kl_loss = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "            init_imgs = batch['init_images'].to(device)                    # [B, init_len, 1, H, W]\n",
    "            inf_imgs = batch['inference_images'].to(device)                # [B, inf_len, 1, H, W]\n",
    "            delta_poses = batch['ground_truth_delta_poses'].to(device)     # [B, inf_len-1, 7]\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            pose_preds, img_preds, kl_loss = model(init_imgs, inf_imgs[:, :-1])\n",
    "    \n",
    "            loss_pose, base_loss, sign_loss = weighted_pose_loss(pose_preds, delta_poses, lambda_sign=1000.0, return_components=True)\n",
    "    \n",
    "            loss_recon = F.mse_loss(img_preds, inf_imgs[:, 1:])\n",
    "    \n",
    "            loss = 5.0 * loss_pose + 1.0 * loss_recon + min(0.5, epoch/20) * kl_loss # warmup epoch = 10\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            total_train_base_loss += base_loss.item()\n",
    "            total_train_sign_loss += sign_loss.item()\n",
    "            total_train_recon_loss += loss_recon.item()\n",
    "            total_train_kl_loss += kl_loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_train_base_loss = total_train_base_loss / len(train_loader)\n",
    "        avg_train_sign_loss = total_train_sign_loss / len(train_loader)\n",
    "        avg_train_recon_loss = total_train_recon_loss / len(train_loader)\n",
    "        avg_train_kl_loss = total_train_kl_loss / len(train_loader)\n",
    "\n",
    "        # ==== Testing ====\n",
    "        model.eval()\n",
    "        total_test_loss = 0.0\n",
    "        all_test_pred = []\n",
    "        all_test_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=f\"Epoch {epoch+1} Eval\"):\n",
    "                # batch keys: 'sequence_name', 'image_sequence', 'inference_images', 'ground_truth_delta_poses'\n",
    "                init_images = batch['init_images'].to(device)           # [B, init_len, 1, H, W]\n",
    "                inf_images = batch['inference_images'].to(device)       # [B, T, 1, H, W]\n",
    "                target_delta_pose = batch['ground_truth_delta_poses'].to(device)  # [B, T-1, 6]\n",
    "\n",
    "                pred_delta_pose = batched_predict_sequence(model, init_images, inf_images, device)\n",
    "\n",
    "                loss = weighted_pose_loss(pred_delta_pose, target_delta_pose)\n",
    "\n",
    "                total_test_loss += loss.item() * 1  # batch=1\n",
    "                all_test_pred.append(pred_delta_pose.cpu().numpy())\n",
    "                all_test_true.append(target_delta_pose.cpu().numpy())\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(test_loader)\n",
    "\n",
    "        # ==== Accuracy Evaluation ====\n",
    "        all_test_pred_arr = np.concatenate(all_test_pred, axis=0).astype(np.float32).reshape(-1, 6)\n",
    "        all_test_true_arr = np.concatenate(all_test_true, axis=0).astype(np.float32).reshape(-1, 6)\n",
    "\n",
    "        pred = all_test_pred_arr  # shape: [N, 6]\n",
    "        true = all_test_true_arr\n",
    "        epsilon = 1e-6\n",
    "        within_bounds = (pred >= 0.5 * (true + epsilon)) & (pred <= 1.5 * (true + epsilon))\n",
    "        true_zero = np.abs(true) < epsilon\n",
    "        pred_zero = np.abs(pred) < epsilon\n",
    "        zero_match = true_zero & pred_zero\n",
    "        correct_mask = within_bounds | zero_match\n",
    "\n",
    "        component_names = ['tx', 'ty', 'tz', 'rx', 'ry', 'rz']\n",
    "        component_accuracies = {\n",
    "            name: correct_mask[:, i].mean()\n",
    "            for i, name in enumerate(component_names)\n",
    "        }\n",
    "        overall_accuracy = np.all(correct_mask, axis=1).mean()\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_train_loss < best_train_loss:\n",
    "            best_train_loss = avg_train_loss\n",
    "            torch.save(model.state_dict(), 'RSSM_7_4_best_model.pth')\n",
    "            print(f\"✅ Best model saved at epoch {epoch+1} with test_loss: {avg_train_loss:.6f}\")\n",
    "        \n",
    "        # Save test results CSV\n",
    "        ratio = (pred + epsilon) / (true + epsilon)\n",
    "        df_test_results = pd.DataFrame({\n",
    "            **{f'pred_{name}': pred[:, i].flatten() for i, name in enumerate(component_names)},\n",
    "            **{f'true_{name}': true[:, i].flatten() for i, name in enumerate(component_names)},\n",
    "            **{f'ratio_{name}': ratio[:, i].flatten() for i, name in enumerate(component_names)},\n",
    "        })\n",
    "        df_test_results.to_csv(f'RSSM_7_4_test_pred_true_epoch_{epoch+1}.csv', index=False)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f}\")\n",
    "        for name in component_names:\n",
    "            print(f\"  {name} acc: {component_accuracies[name]:.4f}\")\n",
    "        print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "        \n",
    "        # Save model and log\n",
    "        #torch.save(model.state_dict(), f'RSSM_6_model_epoch_{epoch+1}.pth')\n",
    "        with open(loss_log_path, mode='a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                epoch + 1,\n",
    "                avg_train_loss, avg_train_base_loss, avg_train_sign_loss, avg_train_recon_loss, avg_train_kl_loss,\n",
    "                avg_test_loss,\n",
    "                component_accuracies['tx'], component_accuracies['ty'], component_accuracies['tz'],\n",
    "                component_accuracies['rx'], component_accuracies['ry'], component_accuracies['rz'],\n",
    "                overall_accuracy\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04086aa2-9e59-44e5-a38c-1e6ea4c30a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████████████████████████████████████████████████████████| 136/136 [07:59<00:00,  3.52s/it]\n",
      "Epoch 1 Eval: 100%|██████████████████████████████████████████████████████████████████| 570/570 [02:12<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 1 with test_loss: 1326.388608\n",
      "[Epoch 1] Train Loss: 1326.3886 | Test Loss: 158.4160\n",
      "  tx acc: 0.0228\n",
      "  ty acc: 0.0175\n",
      "  tz acc: 0.0298\n",
      "  rx acc: 0.0263\n",
      "  ry acc: 0.0070\n",
      "  rz acc: 0.0281\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████████████████████████████████████████████████████████| 136/136 [08:20<00:00,  3.68s/it]\n",
      "Epoch 2 Eval: 100%|██████████████████████████████████████████████████████████████████| 570/570 [02:13<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 1328.6787 | Test Loss: 158.5022\n",
      "  tx acc: 0.0140\n",
      "  ty acc: 0.0105\n",
      "  tz acc: 0.0456\n",
      "  rx acc: 0.0000\n",
      "  ry acc: 0.0123\n",
      "  rz acc: 0.0596\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████████████████████████████████████████████████████████| 136/136 [08:17<00:00,  3.66s/it]\n",
      "Epoch 3 Eval: 100%|██████████████████████████████████████████████████████████████████| 570/570 [02:14<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 3 with test_loss: 1307.545590\n",
      "[Epoch 3] Train Loss: 1307.5456 | Test Loss: 158.8630\n",
      "  tx acc: 0.0070\n",
      "  ty acc: 0.0263\n",
      "  tz acc: 0.0667\n",
      "  rx acc: 0.0158\n",
      "  ry acc: 0.0281\n",
      "  rz acc: 0.0474\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████████████████████████████████████████████████████████| 136/136 [08:20<00:00,  3.68s/it]\n",
      "Epoch 4 Eval: 100%|██████████████████████████████████████████████████████████████████| 570/570 [02:10<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 4 with test_loss: 1292.531276\n",
      "[Epoch 4] Train Loss: 1292.5313 | Test Loss: 159.9182\n",
      "  tx acc: 0.0070\n",
      "  ty acc: 0.0088\n",
      "  tz acc: 0.0193\n",
      "  rx acc: 0.0088\n",
      "  ry acc: 0.0491\n",
      "  rz acc: 0.0439\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████████████████████████████████████████████████████████| 136/136 [08:11<00:00,  3.61s/it]\n",
      "Epoch 5 Eval: 100%|██████████████████████████████████████████████████████████████████| 570/570 [02:19<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 5 with test_loss: 1268.375578\n",
      "[Epoch 5] Train Loss: 1268.3756 | Test Loss: 167.4405\n",
      "  tx acc: 0.0175\n",
      "  ty acc: 0.0351\n",
      "  tz acc: 0.0561\n",
      "  rx acc: 0.0509\n",
      "  ry acc: 0.0281\n",
      "  rz acc: 0.0281\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████████████████████████████████████████████████████████| 136/136 [08:22<00:00,  3.69s/it]\n",
      "Epoch 6 Eval: 100%|██████████████████████████████████████████████████████████████████| 570/570 [02:17<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 6 with test_loss: 1230.767864\n",
      "[Epoch 6] Train Loss: 1230.7679 | Test Loss: 174.1086\n",
      "  tx acc: 0.0193\n",
      "  ty acc: 0.0772\n",
      "  tz acc: 0.1298\n",
      "  rx acc: 0.0175\n",
      "  ry acc: 0.0544\n",
      "  rz acc: 0.0719\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████████████████████████████████████████████████████████| 136/136 [08:35<00:00,  3.79s/it]\n",
      "Epoch 7 Eval: 100%|██████████████████████████████████████████████████████████████████| 570/570 [02:17<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 7 with test_loss: 1218.447977\n",
      "[Epoch 7] Train Loss: 1218.4480 | Test Loss: 187.3296\n",
      "  tx acc: 0.0772\n",
      "  ty acc: 0.0561\n",
      "  tz acc: 0.0368\n",
      "  rx acc: 0.0596\n",
      "  ry acc: 0.0456\n",
      "  rz acc: 0.0105\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████████████████████████████████████████████████████████| 136/136 [08:14<00:00,  3.64s/it]\n",
      "Epoch 8 Eval: 100%|██████████████████████████████████████████████████████████████████| 570/570 [02:16<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 8 with test_loss: 1176.414023\n",
      "[Epoch 8] Train Loss: 1176.4140 | Test Loss: 202.9004\n",
      "  tx acc: 0.0842\n",
      "  ty acc: 0.0825\n",
      "  tz acc: 0.0316\n",
      "  rx acc: 0.0825\n",
      "  ry acc: 0.0456\n",
      "  rz acc: 0.0158\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|██████████████████████████████████████████████████████████████| 136/136 [08:22<00:00,  3.70s/it]\n",
      "Epoch 9 Eval: 100%|██████████████████████████████████████████████████████████████████| 570/570 [02:15<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 1217.6543 | Test Loss: 212.6026\n",
      "  tx acc: 0.0772\n",
      "  ty acc: 0.0737\n",
      "  tz acc: 0.0632\n",
      "  rx acc: 0.0351\n",
      "  ry acc: 0.0737\n",
      "  rz acc: 0.0877\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:20<00:00,  3.68s/it]\n",
      "Epoch 10 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:06<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 10 with test_loss: 1115.563721\n",
      "[Epoch 10] Train Loss: 1115.5637 | Test Loss: 243.4008\n",
      "  tx acc: 0.0456\n",
      "  ty acc: 0.0807\n",
      "  tz acc: 0.0789\n",
      "  rx acc: 0.0333\n",
      "  ry acc: 0.0228\n",
      "  rz acc: 0.1123\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:21<00:00,  3.68s/it]\n",
      "Epoch 11 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:18<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 11 with test_loss: 1062.322677\n",
      "[Epoch 11] Train Loss: 1062.3227 | Test Loss: 205.5043\n",
      "  tx acc: 0.0632\n",
      "  ty acc: 0.0649\n",
      "  tz acc: 0.0491\n",
      "  rx acc: 0.0544\n",
      "  ry acc: 0.1018\n",
      "  rz acc: 0.1000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:14<00:00,  3.64s/it]\n",
      "Epoch 12 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:07<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 12 with test_loss: 983.952059\n",
      "[Epoch 12] Train Loss: 983.9521 | Test Loss: 195.1873\n",
      "  tx acc: 0.0737\n",
      "  ty acc: 0.0561\n",
      "  tz acc: 0.0491\n",
      "  rx acc: 0.0351\n",
      "  ry acc: 0.0947\n",
      "  rz acc: 0.1000\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:29<00:00,  3.75s/it]\n",
      "Epoch 13 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:16<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 13 with test_loss: 927.476587\n",
      "[Epoch 13] Train Loss: 927.4766 | Test Loss: 189.7753\n",
      "  tx acc: 0.0860\n",
      "  ty acc: 0.1000\n",
      "  tz acc: 0.0544\n",
      "  rx acc: 0.0491\n",
      "  ry acc: 0.0982\n",
      "  rz acc: 0.0544\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:13<00:00,  3.63s/it]\n",
      "Epoch 14 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:12<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 14 with test_loss: 878.275080\n",
      "[Epoch 14] Train Loss: 878.2751 | Test Loss: 217.8253\n",
      "  tx acc: 0.0614\n",
      "  ty acc: 0.0526\n",
      "  tz acc: 0.0649\n",
      "  rx acc: 0.0456\n",
      "  ry acc: 0.1053\n",
      "  rz acc: 0.0579\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:28<00:00,  3.74s/it]\n",
      "Epoch 15 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:13<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 15 with test_loss: 832.122329\n",
      "[Epoch 15] Train Loss: 832.1223 | Test Loss: 202.3828\n",
      "  tx acc: 0.0404\n",
      "  ty acc: 0.0561\n",
      "  tz acc: 0.0491\n",
      "  rx acc: 0.0474\n",
      "  ry acc: 0.0509\n",
      "  rz acc: 0.0474\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:29<00:00,  3.74s/it]\n",
      "Epoch 16 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:11<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 16 with test_loss: 783.451001\n",
      "[Epoch 16] Train Loss: 783.4510 | Test Loss: 220.3651\n",
      "  tx acc: 0.0526\n",
      "  ty acc: 0.0702\n",
      "  tz acc: 0.1035\n",
      "  rx acc: 0.0351\n",
      "  ry acc: 0.0421\n",
      "  rz acc: 0.0772\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:26<00:00,  3.72s/it]\n",
      "Epoch 17 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:10<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 17 with test_loss: 779.052930\n",
      "[Epoch 17] Train Loss: 779.0529 | Test Loss: 242.9087\n",
      "  tx acc: 0.0789\n",
      "  ty acc: 0.0632\n",
      "  tz acc: 0.0421\n",
      "  rx acc: 0.0439\n",
      "  ry acc: 0.0123\n",
      "  rz acc: 0.0614\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:23<00:00,  3.70s/it]\n",
      "Epoch 18 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:18<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 18 with test_loss: 751.352255\n",
      "[Epoch 18] Train Loss: 751.3523 | Test Loss: 233.6425\n",
      "  tx acc: 0.0860\n",
      "  ty acc: 0.0439\n",
      "  tz acc: 0.0456\n",
      "  rx acc: 0.0351\n",
      "  ry acc: 0.1053\n",
      "  rz acc: 0.0842\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:27<00:00,  3.73s/it]\n",
      "Epoch 19 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:12<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 19 with test_loss: 710.264894\n",
      "[Epoch 19] Train Loss: 710.2649 | Test Loss: 238.5852\n",
      "  tx acc: 0.0719\n",
      "  ty acc: 0.0895\n",
      "  tz acc: 0.0439\n",
      "  rx acc: 0.0386\n",
      "  ry acc: 0.0877\n",
      "  rz acc: 0.0807\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:25<00:00,  3.71s/it]\n",
      "Epoch 20 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:14<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 20 with test_loss: 666.005596\n",
      "[Epoch 20] Train Loss: 666.0056 | Test Loss: 222.5207\n",
      "  tx acc: 0.0632\n",
      "  ty acc: 0.0807\n",
      "  tz acc: 0.0877\n",
      "  rx acc: 0.0491\n",
      "  ry acc: 0.1018\n",
      "  rz acc: 0.0702\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:18<00:00,  3.66s/it]\n",
      "Epoch 21 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:08<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 21 with test_loss: 652.723612\n",
      "[Epoch 21] Train Loss: 652.7236 | Test Loss: 220.1362\n",
      "  tx acc: 0.0509\n",
      "  ty acc: 0.0860\n",
      "  tz acc: 0.0649\n",
      "  rx acc: 0.0386\n",
      "  ry acc: 0.0737\n",
      "  rz acc: 0.0754\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:14<00:00,  3.64s/it]\n",
      "Epoch 22 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:15<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 22 with test_loss: 624.801705\n",
      "[Epoch 22] Train Loss: 624.8017 | Test Loss: 234.0850\n",
      "  tx acc: 0.0456\n",
      "  ty acc: 0.0772\n",
      "  tz acc: 0.0368\n",
      "  rx acc: 0.0561\n",
      "  ry acc: 0.0807\n",
      "  rz acc: 0.0579\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:23<00:00,  3.71s/it]\n",
      "Epoch 23 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:12<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 23 with test_loss: 608.624064\n",
      "[Epoch 23] Train Loss: 608.6241 | Test Loss: 187.3826\n",
      "  tx acc: 0.0509\n",
      "  ty acc: 0.0667\n",
      "  tz acc: 0.0526\n",
      "  rx acc: 0.0333\n",
      "  ry acc: 0.0807\n",
      "  rz acc: 0.0544\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:22<00:00,  3.69s/it]\n",
      "Epoch 24 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:11<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 24 with test_loss: 599.731410\n",
      "[Epoch 24] Train Loss: 599.7314 | Test Loss: 221.3789\n",
      "  tx acc: 0.0789\n",
      "  ty acc: 0.0737\n",
      "  tz acc: 0.0737\n",
      "  rx acc: 0.0509\n",
      "  ry acc: 0.0877\n",
      "  rz acc: 0.0684\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:35<00:00,  3.79s/it]\n",
      "Epoch 25 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:19<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 25 with test_loss: 585.354499\n",
      "[Epoch 25] Train Loss: 585.3545 | Test Loss: 204.5900\n",
      "  tx acc: 0.0702\n",
      "  ty acc: 0.0825\n",
      "  tz acc: 0.0825\n",
      "  rx acc: 0.0351\n",
      "  ry acc: 0.0912\n",
      "  rz acc: 0.0912\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:30<00:00,  3.75s/it]\n",
      "Epoch 26 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:12<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 26 with test_loss: 555.179184\n",
      "[Epoch 26] Train Loss: 555.1792 | Test Loss: 196.7022\n",
      "  tx acc: 0.0561\n",
      "  ty acc: 0.0509\n",
      "  tz acc: 0.0789\n",
      "  rx acc: 0.0596\n",
      "  ry acc: 0.0719\n",
      "  rz acc: 0.0316\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:26<00:00,  3.73s/it]\n",
      "Epoch 27 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:11<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] Train Loss: 556.5342 | Test Loss: 225.2395\n",
      "  tx acc: 0.0175\n",
      "  ty acc: 0.0842\n",
      "  tz acc: 0.0702\n",
      "  rx acc: 0.0491\n",
      "  ry acc: 0.1193\n",
      "  rz acc: 0.0842\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:23<00:00,  3.70s/it]\n",
      "Epoch 28 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:15<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 28 with test_loss: 535.857659\n",
      "[Epoch 28] Train Loss: 535.8577 | Test Loss: 222.5468\n",
      "  tx acc: 0.0579\n",
      "  ty acc: 0.0947\n",
      "  tz acc: 0.0772\n",
      "  rx acc: 0.0561\n",
      "  ry acc: 0.0491\n",
      "  rz acc: 0.0649\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:17<00:00,  3.66s/it]\n",
      "Epoch 29 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:12<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 29 with test_loss: 520.995193\n",
      "[Epoch 29] Train Loss: 520.9952 | Test Loss: 216.9099\n",
      "  tx acc: 0.0474\n",
      "  ty acc: 0.0702\n",
      "  tz acc: 0.0684\n",
      "  rx acc: 0.0386\n",
      "  ry acc: 0.1018\n",
      "  rz acc: 0.0842\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:19<00:00,  3.67s/it]\n",
      "Epoch 30 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:10<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 30 with test_loss: 516.510718\n",
      "[Epoch 30] Train Loss: 516.5107 | Test Loss: 235.6913\n",
      "  tx acc: 0.0702\n",
      "  ty acc: 0.0526\n",
      "  tz acc: 0.0579\n",
      "  rx acc: 0.0579\n",
      "  ry acc: 0.0965\n",
      "  rz acc: 0.0491\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:22<00:00,  3.70s/it]\n",
      "Epoch 31 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:20<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 31 with test_loss: 501.128400\n",
      "[Epoch 31] Train Loss: 501.1284 | Test Loss: 229.4188\n",
      "  tx acc: 0.0632\n",
      "  ty acc: 0.0526\n",
      "  tz acc: 0.0614\n",
      "  rx acc: 0.0509\n",
      "  ry acc: 0.1053\n",
      "  rz acc: 0.0404\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 Training: 100%|█████████████████████████████████████████████████████████████| 136/136 [08:22<00:00,  3.70s/it]\n",
      "Epoch 32 Eval: 100%|█████████████████████████████████████████████████████████████████| 570/570 [02:08<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32] Train Loss: 512.5586 | Test Loss: 215.8318\n",
      "  tx acc: 0.0544\n",
      "  ty acc: 0.0474\n",
      "  tz acc: 0.0526\n",
      "  rx acc: 0.0772\n",
      "  ry acc: 0.0895\n",
      "  rz acc: 0.0123\n",
      "Overall Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 Training:  74%|████████████████████████████████████████████▊                | 100/136 [06:17<02:30,  4.18s/it]"
     ]
    }
   ],
   "source": [
    "# === Run ===\n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        csv_path=\"poses_combined.csv\",\n",
    "        train_dirs=train_dirs,\n",
    "        test_dirs=test_dirs,\n",
    "        epochs=40,\n",
    "        batch_size=16,\n",
    "        lr=1e-4,\n",
    "        image_size=(256, 256)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3206f58d-7ca6-4011-9724-2494fd027e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bmilab)",
   "language": "python",
   "name": "bmilab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
